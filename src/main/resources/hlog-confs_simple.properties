#=======================================不可动态部分=======================================
# #######日志收集代码织入配置#######
#配置捕获的基础路径，代理会在这些路径下的所有类的方法上织入所需要的代码，默认所有的开关都是关闭

hlog.base.path.com.asiainfo.crm = process
hlog.base.path.org.springframework.web.servlet#DispatcherServlet.doDispatch = session,http.request,receive.id
hlog.base.path.com.ai.aif.csf.protocol.http.server.access#HttpAccessImpl.doPost = http.request,receive.id
hlog.base.path.com.asiainfo.crm.bcomm.utils#LogHelper.writeLog = interceptRet:$tableName
hlog.base.path.com.al.crm.nosql.multilevel.util#HlogUtil.hook = intercept:mlcache
hlog.base.path.com.asiainfo.crm.bcomm.utils#HlogCollectHelper = interceptRet:crmsrv
#hlog.base.path.com.asiainfo.crm.bcomm.utils#HlogCollectHelper.clientServiceInfo = interceptRet:crmsrv1

hlog.base.path.com.asiainfo.crm.bcomm#LogIdUtils = hlog.id
hlog.base.path.com.aictcrm.comm.mq.util#LogIdUtils = hlog.id
hlog.base.path.com.asiainfo.crm.bcomm#Helper.getUid = group.id
hlog.base.path.com.ai.aif.csf.log#LogIdUtils = hlog.id


hlog.exclude.paths = com.*RedisConnStatusMgrThread,com.*AsynchronizedCacheTask,com.*AbstractInfiniteLoopTask,com.*DefaultTaskPool,com.*DefaultFileTailer,com.*AbstractCache,com.al.crm.asynframe.*,com.al.crm.nosql.*,com.al.crm.log.*,com.*UniqueHashMap,com.*\$EnhancerByCGLIB+.*,com.*.vo.*,com.*.model.*,com.asiainfo.crm.bcomm.*,com.asiainfo.crm.comm.util.*
hlog.exclude.methods = com.*returnResource,com.*getServerPort,*$*
hlog.exclude.paramTypes = com.linkage.bss.crm.so.plugin.core.PluginModel
hlog.exclude.paramType.paths = weblogic,com.bea
#=======================================可动态部分=======================================
#全局开关标志，当全局开关为off时将关闭所有的捕获，如果全局为on时具体看指定子目录的开关
hlog.enable = true
hlog.enable.request = true
hlog.enable.save.without.params = true
hlog.enable.save.without.subs = false
hlog.enable.http.track = true
hlog.enable.receive.logid = true
hlog.enable.logger.track = true
hlog.enable.logger.level = all
hlog.enable.sql.track = true
hlog.enable.exclude.get.set.method = false
#数据库连接事务耗时
hlog.enable.transaction = true
hlog.enable.get.conn.cost = true
hlog.enable.session = true
hlog.session = user.role.name
hlog.enable.dynamic.process = true
hlog.process.time = -1
#执行时间超过多少算是例外耗时时长,0都记录
hlog.process.time.without = -1
hlog.sql.time = 0
hlog.enable.csf.header = true

#logger.error是否使用hlog.rate采样率，默认true
hlog.rate.enable.logger.error = false

#采集率，百分比值，范围0~100，配10%
hlog.rate=10
#服务统计采样率，单独计算,跟hlog.rate没任何关系，百分比值，范围0~100，配10%
hlog.rate.crmsrv=10
#配置全采集的工号白名单，不受hlog.rate采样影响
hlog.collect.staffCode=3300134,0900991
#白名单工号对应的sql时间阀值，不配的话使用hlog.sql.time配值，配10ms
hlog.collect.staffCode.sql.time = 10
#白名单工号对应的方法时间阀值，不配的话使用hlog.process.time配值，配2ms
hlog.collect.staffCode.process.time = 2

#方法调用栈深度限制，主要针对递归调用
#hlog.limit.stack.size = -1

#配置自定义的消息处理器,下面为堆为内存
#hlog.reveriver.class=com.asiainfo.hlog.client.reveiver.DirectReveiver
#hlog.direct.minsize = 0
#hlog.direct.increment = 102400
#hlog.direct.maxsize = 409600
#hlog.direct.maxqueue = 50
#配置异常编码
#hlog.error.code.types=code,spec
#jvm采集
hlog.enable.monitor.jvm = true
#jvm采集时间间隔
hlog.monitor.jvm.interval.time = 5

#循环监控开关
hlog.enable.monitor.loop = false
#循环监控任务执行间隔时间，单位秒
hlog.monitor.loop.interval.time = 1
#循环监控死循环判时间，单位秒
hlog.monitor.loop.timeout = 15


hlog.capture.logger.enable.paths = com.asiainfo.crm,studio.raptor.ddal.core.engine,com.ai.vita,studio.raptor.extractor,studio.raptor.dispatcher,com.aictcrm.comm.mq,com.ai.aif.csf,com.al.crm.nosql.multilevel,com.al.uniconfig
hlog.capture.enable.com.ai.aif.csf = error,logger.error
hlog.capture.enable.com.aictcrm.comm.mq = error,logger.debug
hlog.capture.enable.com.al.crm.nosql.multilevel = error,logger.info
hlog.capture.enable.def = process,error,sql,intercept,interceptRet,logger.debug

hlog.capture.handler.def = crmKafka,console
hlog.handler.crmKafka = kafka


##----------------------------------需要注意和修改点-----------------------------
#根据实际的kafka地址配置
hlog.handler.crmKafka.kafkaConfig.bootstrap.servers=133.37.135.37:19092
#kafka参数配置格式
#hlog.handler.crmKafka.kafkaConfig.xxx.xx=xxx

#注：这里的topic需要与hlog-server的消费topic一样
#hlog.handler.crmKafka.topic.name=hlog-app-topic
hlog.handler.crmKafka.topic.name = $mc
#hlog业务日志的topic映射关系

#hlog通用日志的topic映射关系
hlog.handler.crmKafka.topic.mapping.sevtrack,crmsrv = hlog-crm3-comm-service-tracking
hlog.handler.crmKafka.topic.mapping.request = hlog-crm3-comm-req-elapsed-time
hlog.handler.crmKafka.topic.mapping.process,sql,tran = hlog-crm3-comm-consum
hlog.handler.crmKafka.topic.mapping.error = hlog-crm3-comm-error
hlog.handler.crmKafka.topic.mapping.logger = hlog-crm3-comm-logger
hlog.handler.crmKafka.topic.mapping.params = hlog-crm3-comm-params
hlog.handler.crmKafka.topic.mapping.loop,jvm = hlog-crm3-comm-trouble
hlog.handler.crmKafka.topic.mapping.RULE_INVOKE_LOG_DETAIL,RULE_EXECUTE_DETAIL_HLOG,RULE_SOURCE_COST_HLOG = hlog-crm3-order
hlog.handler.crmKafka.topic.mapping.HLOG_ORDER_BEFORE_CHAIN,HLOG_ORDER_AFTER_CHAIN,CHAIN_RUN_TIME_HLOG,CHAIN_SOURCE_COST_HLOG = hlog-crm3-order
hlog.handler.crmKafka.topic.mapping.TRANSACT_LOG,MESSAGE_ORDER,GROUP_ORDER_CHECKED = hlog-crm3-intf-eop
hlog.handler.crmKafka.topic.mapping.SO_ONE_ITEM_RESULTS = hlog-crm3-so
#hlog平台日志的topic映射关系

#如果未配置topic映射关系，都指派到hlog-crm3-comm-undef
hlog.handler.crmKafka.topic.mapping.def = hlog-crm3-comm-undef


hlog.reveriver.mem.queue.full.discarded = true
hlog.reveriver.mem.queue.size = 10000
hlog.reveriver.each.quantity = 400
hlog.reveriver.frequency = 10
hlog.reveriver.threadnum = 5

hlog.id.zk.servers=192.168.1.24:2181,192.168.1.24:2182,192.168.1.24:2183
hlog.id.start=9000
hlog.id.end=9999
hlog.log.enable = true

#kafka消息最大报文长度，默认1048576字符，超过max.length并超过max.bytes按hlog.msg.cut.length进行截取，如果配置小于0，不截取和发警告
hlog.msg.max.length=1048576
#kafka消息最大报文字节数，默认1048576字节（1M）
hlog.msg.max.bytes=1048576
#kafka消息大字段截取大小，默认5000个字符
hlog.msg.cut.length=5000
#方法循环次数告警，默认100次
hlog.loop.times=100