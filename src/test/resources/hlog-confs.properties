#uniconfig.enabled=true
###统一配置平台服务器地址
#uniconfig.serverPorts=192.168.1.130:8282
#uniconfig.envType=TEST_ENV
###应用系统的代码（或系统名）
#uniconfig.domain=hlog


#-----------不可动态部分-----------------

#全局开关标志，当全局开关为off时将关闭所有的捕获，如果全局为on时具体看指定子目录的开关
hlog.enable=true
#配置捕获的基础路径，代理会在这些路径下的所有类的方法上织入所需要的代码，默认所有的开关都是关闭
hlog.base.path.com.al.crm=error:h110,process
hlog.base.path.org.apache.ibatis.binding=process
#指定方法采集入参
hlog.base.path.com.al.crm.demo.simple.mvc#SimpleController.findDeveloperByMap=interceptParam:test00
#第三方日志框架
hlog.base.path.org.apache.log4j#Category=logger
hlog.base.path.ch.qos.logback.classic#Logger,org.slf4j.impl#Log4jLoggerAdapter,org.slf4j.helpers#NOPLogger=logger
#hlog.exclude.paths=com.asiainfo.test.Parent


#开源日志框架的输出级别，默认是error
hlog.level.com.al.crm=debug
#开启指定目录的日志收集类型，如下表示在com.asiainfo.cust目录下收集log4j和process两个日志
hlog.capture.enable.com.al.crm=error,process,logger
hlog.capture.enable.org.apache.ibatis.binding=process
hlog.capture.enable.com.al.crm.demo.simple.mvc#SimpleController.findDeveloperByMap=interceptParam

#对收集到的日志数据配置相应的处理器
hlog.capture.handler.com.al.crm,org.apache.ibatis.binding=console,testKafka
#hlog.capture.handler.org.apache.ibatis.binding=console,testKafka

hlog.handler.testKafka=kafka
hlog.handler.testKafka.metadata.broker.list=192.168.2.142:9092
#hlog.handler.testKafka.metadata.broker.list=192.168.1.228:9092
hlog.handler.testKafka.request.timeout.ms=300
#hlog.handler.testKafka.topic.name=hlog-test0-topic
hlog.handler.testKafka.topic.name=topic1
hlog.handler.testKafka.producer.type=async
hlog.handler.testKafka.queue.buffering.max.ms=2000
#hlog.handler.testKafka.batch.num.messages=50
hlog.handler.testKafka.keyed.message.size=80
#hlog.capture.handler.com.asiainfo.test#TestApp2=console

#hlog
hlog.reveriver.mem.queue.size=20000
hlog.reveriver.each.quantity=480
